# -*- coding: utf-8 -*-
"""project_20745522Castro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e9v5IWQnrk3n6HlKDlTx_MVKcFPHzNPB
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from tqdm import tqdm
import numpy as np
from torchvision.models import resnet50
from torch.autograd import Variable
import os
from natsort import natsorted
import pandas as pd

# Set device (GPU if available, else CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

from google.colab import drive
drive.mount('/content/drive')
path = '/content/drive/MyDrive/uw-syde572-fall23/5_shot/5_shot' # I placed the images in my drive
folder_path = os.listdir(path)
# Define the paths to the training and test image folders
train_path = os.path.join(path, 'train')
test_path = os.path.join(path, 'test')

class CustomDataset(Dataset):
    def __init__(self,  root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = os.listdir(root_dir)
        self.image_names = os.listdir(root_dir)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.images[idx])
        image = Image.open(img_name).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image, self.image_names[idx]

class ImageFolderCustom(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes, self.class_to_idx = self.find_classes()
        self.images, self.targets = self.make_dataset()

    def find_classes(self):
        classes = natsorted([d.name for d in os.scandir(self.root_dir) if d.is_dir()])
        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        return classes, class_to_idx

    def make_dataset(self):
        images = []
        targets = []
        for target_class in self.classes:
            class_index = self.class_to_idx[target_class]
            class_path = os.path.join(self.root_dir, target_class)
            for root, _, fnames in sorted(os.walk(class_path)):
                for fname in natsorted(fnames):
                    path = os.path.join(root, fname)
                    images.append((path, class_index))
                    targets.append(class_index)
        return images, targets
    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        path, target = self.images[index]
        img = Image.open(path).convert('RGB')

        if self.transform is not None:
            img = self.transform(img)

        return img, target

# Function to calculate mean and std
def calculate_mean_std(dataloader):
    # Variables to store sum and squared sum of all pixels
    sum_rgb = torch.tensor([0.0, 0.0, 0.0])
    sum_rgb_squared = torch.tensor([0.0, 0.0, 0.0])
    num_pixels = 0

    for images, _ in tqdm(dataloader):
        # Sum up the pixel values and squared pixel values for each channel
        sum_rgb += images.sum(dim=[0, 2, 3])
        sum_rgb_squared += (images ** 2).sum(dim=[0, 2, 3])
        num_pixels += images.numel() // images.size(1)  # Total number of pixels per channel

    # Calculate mean and standard deviation
    mean_rgb = sum_rgb / num_pixels
    std_rgb = torch.sqrt(sum_rgb_squared / num_pixels - mean_rgb ** 2)

    return mean_rgb, std_rgb

# Define the transform to convert images to tensors
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

dataset = ImageFolderCustom(root_dir=train_path, transform=transform)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# Calculate mean and std
mean, std = calculate_mean_std(dataloader)
print(f"Mean: {mean}")
print(f"Std: {std}")

# Create transform for test dataset to transform to tensors and normalize
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.3930, 0.3980, 0.3995], std=[0.1621, 0.1603, 0.1595]),
])

# Create data augmentation transforms for the train dataset
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.RandomApply([
        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),
        transforms.RandomAdjustSharpness(sharpness_factor=2)
    ], p=0.5),
    transforms.Normalize(mean=[0.3930, 0.3980, 0.3995], std=[0.1621, 0.1603, 0.1595]),  # Normalization values calculated from mean and std of training dataset
])

import matplotlib.pyplot as plt
import torchvision
from torchvision import transforms
from torch.utils.data import DataLoader
import torch
from PIL import Image
import os
from natsort import natsorted
import numpy as np

# Assuming ImageFolderCustom and train_transform are defined

# Create dataset and dataloader
train_dataset = ImageFolderCustom(root_dir=train_path, transform=train_transform)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

# Function to show an image
def imshow(img):
    img = img.numpy().transpose((1, 2, 0))
    plt.imshow(img)
    plt.show()

# Get a batch of training data
dataiter = iter(train_loader)
images, labels = next(dataiter)

# Make a grid from batch and show images
out = torchvision.utils.make_grid(images)
imshow(out)

# Create datasets
train_dataset = ImageFolderCustom(root_dir=train_path, transform=train_transform)
test_dataset = CustomDataset(root_dir=test_path, transform=test_transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)

# define number of classes
num_classes = len(train_dataset.classes)

# Initialize the ResNet50 model
model = models.resnet50(pretrained=True)

# Freeze all parameters in the model
for param in model.parameters():
    param.requires_grad = False

# Get the number of features from the input layer of the model's classifier
num_ftrs = model.fc.in_features

# Define a new classifier (fully connected layer) with BatchNorm and Dropout
classifier = nn.Sequential(
    nn.BatchNorm1d(num_ftrs),  # BatchNorm before first linear layer
    nn.Linear(num_ftrs, 512),
    nn.Dropout(0.5),
    nn.ReLU(),
    nn.BatchNorm1d(512),
    nn.Linear(512, num_classes),
)

# Replace the model's classifier with the new classifier
model.fc = classifier

model = model.to(device)

# Using SGD with a slightly adjusted learning rate and momentum
optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)
#optimizer = optim.Adam(model.fc.parameters(), lr=0.01)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

# Loss function
criterion = nn.CrossEntropyLoss()

# Training loop
num_epochs = 30
loss_values = []
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:  # Assuming train_loader is defined
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    # Print loss for every epoch
    epoch_loss = running_loss / len(train_loader)
    loss_values.append(epoch_loss)
    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')
    scheduler.step(epoch_loss)

# Plotting epoch vs loss
plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', color='b')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Epoch vs Loss Resnet-50')
plt.grid(True)
plt.show()

# Testing the model
model.eval()
# Lists to store predictions and image names
predictions = []

with torch.no_grad():
    for inputs, image_names in tqdm(test_loader, desc='Testing'):
        # Move inputs to the device
        inputs = inputs.to(device)
        # Forward pass
        outputs = model(inputs)
        # Get predictions from the maximum value
        _, preds = torch.max(outputs, 1)
        # Store predictions and image names
        predictions.extend([(image_name, int(pred)) for image_name, pred in zip(image_names, preds.cpu().numpy())])

df = pd.DataFrame(predictions, columns=['id', 'category'])
df['id'] = df['id'].apply(lambda x: x.replace('.jpg', ''))
#print(df)

predictions = natsorted(predictions)
df = pd.DataFrame(predictions, columns=['id', 'category'])
df['id'] = df['id'].apply(lambda x: x.replace('.jpg', ''))
#print(df)

# save predictions to csv
output_csv_path = os.path.join(path, 'submission1.csv')
df.to_csv(output_csv_path, index=False)

import pandas as pd

# Load the CSV file into a DataFrame
csv_path = os.path.join(path, 'submission1.csv')
df = pd.read_csv(csv_path)

# Define the known counts (number of images per category)
known_counts = {
    '0': 28, '1': 27, '2': 29, '3': 17, '4': 29, '5': 17, '6': 24,
    '7': 25, '8': 27, '9': 19, '10': 21, '11': 27, '12': 17, '13': 20,
    '14': 25, '15': 25, '16': 21, '17': 29, '18': 25, '19': 16, '20': 23, '21': 25
}

# Initialize a counter for the starting index of each category
start_index = 0

# Create a list to store the match results (1 for match, 0 for mismatch)
matches = []

# Loop through each category and its count
for category, count in known_counts.items():
    # Get the predicted categories for the current known category range
    predicted_categories = df.loc[start_index:start_index + count - 1, 'category']

    # Check if the predicted categories match the known category
    # Assign 1 for matches and 0 for mismatches
    match_results = [1 if int(cat) == int(category) else 0 for cat in predicted_categories]

    # Extend the matches list with the match results
    matches.extend(match_results)

    # Update the start index for the next category
    start_index += count

# Calculate the accuracy
accuracy = sum(matches) / 517  # 517 is the total number of images

print(f'Accuracy: {accuracy}')

# define number of classes
num_classes = len(train_dataset.classes)

# load pretrained model denseNet121
model = models.densenet121(pretrained=True)

for param in model.parameters():
    param.requires_grad = False
num_ftrs = model.classifier.in_features
classifier = nn.Sequential(
    nn.BatchNorm1d(num_ftrs), # BatchNorm before Dropout
    nn.Dropout(0.5),
    nn.Linear(num_ftrs, 512),
    nn.ReLU(),
    nn.BatchNorm1d(512), # BatchNorm before Dropout
    nn.Linear(512, num_classes)
)

# Replace the model's classifier with the new classifier
model.classifier = classifier

model = model.to(device)

# Using SGD with a slightly adjusted learning rate and momentum
optimizer = optim.SGD(model.classifier.parameters(), lr=0.01, momentum=0.9)
#optimizer = optim.Adam(model.fc.parameters(), lr=0.01)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

# Loss function
criterion = nn.CrossEntropyLoss()

# Training loop
num_epochs = 30
loss_values = []
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:  # Assuming train_loader is defined
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    # Print loss for every epoch
    epoch_loss = running_loss / len(train_loader)
    loss_values.append(epoch_loss)
    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')
    scheduler.step(epoch_loss)

# Plotting epoch vs loss
plt.plot(range(1, num_epochs + 1), loss_values, marker='o', linestyle='-', color='r')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Epoch vs Loss DenseNet')
plt.grid(True)
plt.show()

# Testing the model
model.eval()
# Lists to store predictions and image names
predictions = []

with torch.no_grad():
    for inputs, image_names in tqdm(test_loader, desc='Testing'):
        # Move inputs to the device
        inputs = inputs.to(device)
        # Forward pass
        outputs = model(inputs)
        # Get predictions from the maximum value
        _, preds = torch.max(outputs, 1)
        # Store predictions and image names
        predictions.extend([(image_name, int(pred)) for image_name, pred in zip(image_names, preds.cpu().numpy())])

df = pd.DataFrame(predictions, columns=['id', 'category'])
df['id'] = df['id'].apply(lambda x: x.replace('.jpg', ''))
print(df)

predictions = natsorted(predictions)
df = pd.DataFrame(predictions, columns=['id', 'category'])
df['id'] = df['id'].apply(lambda x: x.replace('.jpg', ''))
print(df)

# save predictions to csv
output_csv_path = os.path.join(path, 'submission2.csv')
df.to_csv(output_csv_path, index=False)

import pandas as pd

# Load the CSV file into a DataFrame
csv_path = os.path.join(path, 'submission2.csv')
df = pd.read_csv(csv_path)

# Define the known counts (number of images per category)
known_counts = {
    '0': 28, '1': 27, '2': 29, '3': 17, '4': 29, '5': 17, '6': 24,
    '7': 25, '8': 27, '9': 19, '10': 21, '11': 27, '12': 17, '13': 20,
    '14': 25, '15': 25, '16': 21, '17': 29, '18': 25, '19': 16, '20': 23, '21': 25
}

# Initialize a counter for the starting index of each category
start_index = 0

# Create a list to store the match results (1 for match, 0 for mismatch)
matches = []

# Loop through each category and its count
for category, count in known_counts.items():
    # Get the predicted categories for the current known category range
    predicted_categories = df.loc[start_index:start_index + count - 1, 'category']

    # Check if the predicted categories match the known category
    # Assign 1 for matches and 0 for mismatches
    match_results = [1 if int(cat) == int(category) else 0 for cat in predicted_categories]

    # Extend the matches list with the match results
    matches.extend(match_results)

    # Update the start index for the next category
    start_index += count

# Calculate the accuracy
accuracy = sum(matches) / 517  # 517 is the total number of images

print(f'Accuracy: {accuracy}')